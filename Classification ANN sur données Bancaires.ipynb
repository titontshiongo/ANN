{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1caa9b0b",
   "metadata": {},
   "source": [
    "\n",
    "Projet de construction d'un modèle qui tentera de prédire si quelqun remboursera ou non son prêt en se basant sur des informations historiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339768bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ae614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import du jeu de données\n",
    "df=pd.read_csv('lending_club_loan_two.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00b2f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2187b13e",
   "metadata": {},
   "source": [
    "# Analyse Exploratoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un graphique de comptage pour la variable cible\n",
    "sns.countplot(x='loan_status',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd922f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un histogramme pour les varibales continues. exemple pour voir la distribution des montants accordés\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.distplot(df['loan_amnt'],kde=False,bins=40)\n",
    "plt.xlim(0,45000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f23739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de la corrélation entre toutes les variables continues en utilisant la méthode .corr()\n",
    "#df.corr()\n",
    "# Visualisation avec une heatmap\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(df.corr(),annot=True,cmap='viridis')\n",
    "plt.ylim(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e7f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constat d'une relation presque parfaite avec la feature 'installment'\n",
    "# Exploration de cette feature en effectuant un nuage de point et voir si cette relation a du sens avec la variable à prédire\n",
    "# on veut s'assurer ne pas avoir de fuite de données avec cette feature dans notre label\n",
    "# on doit toujours être sur qu'il n'y a pas 1 seul feature qui serait un parfait prédicteur du label à prédire car cela signifirait qu'il ne s'agit pas\n",
    "# d'une simple feature mais probablement d'information dupliqué qui serait très similaire au label\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x='installment',y='loan_amnt',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc045bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un box plot montrant la relation entre l'état du prêt (loan_status) et le montant du prêt\n",
    "# permet de répondre si il y a une relation entre les emprunt très elevé VS enprunt peu élevé et le fait qu'il soit totalement soldé\n",
    "sns.boxplot(x='loan_status',y='loan_amnt',data=df)\n",
    "# En moyenne la boîte charged off(emprunts non soldés) est légèrement plus haute  ce qui signifie que lorsque le montant de prêt est élevé\n",
    "# on a plus de chance que l'emprunt ne soit pas remboursé, logique car plis difficile de rembourser des montants élevés que des plus petits montants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc80d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calucl de stats sommaires pour les montants du prêt regroupés  par la feature loan status\n",
    "df.groupby('loan_status')['loan_amnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2338b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration des colonnes Grade et subGrade que lending_club attribue aux prêts: voir les notations et sous notations possibles\n",
    "#df['grade'].unique()\n",
    "df['sub_grade'].unique()\n",
    "# on constate que les sous notations contiennent les infos des notations réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un graphique de comptage par notation (grade) et en définissant 'loan_status' avec le paramètre 'hue'\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.countplot(x='grade',data=df,hue='loan_status')\n",
    "# on peut voir qu'i ya une différenciation entre les emprunts totalement rembournés et les non remboursés selon la notation du crédit \n",
    "# on peut voir le pourcentage d'emprunt non remboursé augmente à mesure que les lettres augmentent\n",
    "# A la lettre G on constate que 50% d'emprunt sont remboursés et 50% d'emprunts sont non remboursés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e469606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage d'un graphique de comptage par sous_notation (sub_grade) de qualité de prêt\n",
    "# il s'agit de la distribution à travers tous le dataset : combiende A1 on dispose et ....\n",
    "# on constate majoritairement que les crédits sont de notations A,B,C,D--> représentant les crédits les moins risqués qui ont moins de chance pas être remboursé\n",
    "plt.figure(figsize=(12,4))# pour redimensionner le graphique\n",
    "subgrade_order=sorted(df['sub_grade'].unique())#  triage sur les sous notations avec l'appel de la fonction 'sorted'\n",
    "sns.countplot(x='sub_grade',data=df,order=subgrade_order, palette='coolwarm')\n",
    "# Les meilleures notations sont en bleu et les pires sont en rouges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d61f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph qui nous permet de comparer par sous notation la ration compètement remboursé VS non Remboursé\n",
    "plt.figure(figsize=(12,4))# pour redimensionner le graphique\n",
    "subgrade_order=sorted(df['sub_grade'].unique())#  triage sur les sous notations avec l'appel de la fonction 'sorted'\n",
    "sns.countplot(x='sub_grade',data=df,order=subgrade_order, palette='coolwarm',hue='loan_status')\n",
    "# pour les pires notations le taux de fully_paid et charged off sont presque les mêmes \n",
    "# ce qui semble pertinent d'investiguer si c'est pertinent d'accorder des prêts au client ayant ces notations F ou G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af22c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il semble que F et G ne sont pas remboursés très souvent: création d'un graph de comptage en isolant nos deux notations\n",
    "f_and_g=df[(df['grade']== 'G') |(df['grade']=='F')]# création d'un sous dataframe en filtrant sur nos deux notations\n",
    "plt.figure(figsize=(12,4))# pour redimensionner le graphique\n",
    "subgrade_order=sorted(f_and_g['sub_grade'].unique())#  \n",
    "sns.countplot(x='sub_grade',data=f_and_g,order=subgrade_order, palette='coolwarm',hue='loan_status')# utilisation du dataframe filtré\n",
    "# si le client est noté à G5 il est presqu'aussi probable qu'il rembouse totalement l'emprunt et qu'il ne rembourse pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4208916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une nouvelle colonne  'loan_repaid' qui contiendra 1 si le statut du prêt était fully_paid et o si charged off\n",
    "# qui sera notre label à prédire\n",
    "df['loan_repaid']= df['loan_status'].map({'Fully Paid':1,'Charged Off':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9bcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['loan_repaid','loan_status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c452bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un diagramme en barre (bar plot) entre les features numériques et la nouvelle colonne et la nouvelle colonne laon_repaid qui est notre label\n",
    "\n",
    "df.corr()['loan_repaid'].sort_values()[:-1].plot(kind='bar')\n",
    "df.corr()['loan_repaid'].sort_values().drop('loan_repaid').plot(kind='bar')\n",
    "# Pour quelle feature numérique à la plus grande corrélation avec notre label\n",
    "# int_rate est négativement fortmement corrélé : si le taux d'int est élevé on a plus de difficulté à rembourser l'emprunt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4da75",
   "metadata": {},
   "source": [
    "# Traitement des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir la série en pourcentage du totale du data frame\n",
    "#df.isnull().sum()\n",
    "df.isnull().sum()/len(df)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb11259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features emp_title et emp_length voir si il est possible de les supprimer \n",
    "# Combien y a t-il d'emploi unique?\n",
    "df['emp_title'].nunique()\n",
    "# on obtient une tonne de métier différent parmis les emprunteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emp_title'].value_counts()\n",
    "# Il y a trop de titres de postes uniques pour essayer de les convertir en une feature de vraibles dummy. on va donc supprimer cette colone\n",
    "# comme solution(Feature_engineering), on peut catégoriser ces métiers comme métiers à haut revenu, revenus moyen et faible revenu\n",
    "# il faut mapper 37076 titre de job différents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047355e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression de la colonne emp_title\n",
    "df=df.drop('emp_title',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ba7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un graphique de comptage de la colonne emp_length en faisant un tri\n",
    "sorted(df['emp_length'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e88d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_length_order=['< 1 year','1 year',\n",
    " '2 years',\n",
    " '3 years',\n",
    " '4 years',\n",
    " '5 years',\n",
    " '6 years',\n",
    " '7 years',\n",
    " '8 years',\n",
    " '9 years',\n",
    " '10+ years']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x='emp_length',data=df,order=emp_length_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b86f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer un décompte avec un paramètre hue de séparation entre Fully Paid et Charged Off\n",
    "# l'état de l'emrunt si soldé ou non\n",
    "# relation entre Fully Paid et charged Off par durée d 'emploi\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.countplot(x='emp_length',data=df,order=emp_length_order,hue='loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c99b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on veut savoir le pourcentage de personnes par catégories d'emploi qui n'ont pas remboursé leur prêt\n",
    "emp_co=df[df['loan_status']=='Charged Off'].groupby('emp_length').count()['loan_status'] # selection des personnes qui  n'ont pas remboursé et on les groupe par durée d'emploi puis on les compt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939e2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_fp=df[df['loan_status']=='Fully Paid'].groupby('emp_length').count()['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00fec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention du rato entre les deux séries\n",
    "# pourcentage des personnes qui sont soldés leur emprunt VS ceux qui n'ont pas soldés\n",
    "emp_len=emp_co/(emp_fp+ emp_co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_len.plot(kind='bar')\n",
    "# Différence pas assez significative pour conserver cette feature\n",
    "# du fait de la siilarité des résultats quelque soit la catéforie durée d'emploi on peut supprimer cette feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('emp_length',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examinons le titre du prêt Vs colonne purpose\n",
    "df['purpose'].head()\n",
    "#df['title'].head()\n",
    "# suppression de la colonne title car les infos fournis sont identiques à purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('title',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed653c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable mort_acc: création d'un graph de contage\n",
    "df['mort_acc'].value_counts()\n",
    "# la majorité des personnes ont o autres compte d'hypothèques représentant 25% des données\n",
    "# Approche pour traiter les données manquantes c'est de découvrir une feature qui a toute l'information qui aurait une très forte corrélation avec mort_acc\n",
    "# voir ensuite si on peut l'utiliser pour compléter 'info manquante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecf5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# détermination de la colonne qui fortmement corrélé avec mort_acc\n",
    "df.corr()['mort_acc'].sort_values\n",
    "# total_acc semble avoir une bonne corrélation positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da66e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regroupement du dataframe par total_acc et calculon la valeur moyenne de mort_acc par entrée de total_acc en utilisant la méthode fillna()\n",
    "total_acc_avg=df.groupby('total_acc').mean()['mort_acc']\n",
    "# pour le remplacement des valeurs manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c81f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction d'une fonction pour remplir les valeurs manquantes d'un data frame avec deux colonnes \n",
    "def fill_mort_acc(total_acc,mort_acc):\n",
    "  if np.isnan(mort_acc):\n",
    "    return total_acc_avg['total_acc']\n",
    "  else:\n",
    "    return mort_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48411c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des colones revo_util et pub_reck_bankcies représentent moins de 0.5% du dataset en utilisant la méthode dropna()\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb62247",
   "metadata": {},
   "source": [
    "# Traitement des données catégoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb43cd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lister toutes les colonnes catégoriques: utilisation de la méthode d_types\n",
    "df.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature term\n",
    "df['term'].value_counts()\n",
    "# colone binaire soit 36 mois soit 60 mois \n",
    "# transformation en colonne numérique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['term']=df['term'].apply(lambda term: int(term[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d39fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81735fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feauture grade\n",
    "df['grade'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de965f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression de la feature grade car toutes les infos sont dans la feature sub_grade\n",
    "df=df.drop('grade',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17d6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion de subgrades en variables dummies puis on va les concatener au datframe d'origine\n",
    "# puis supprimer subgrade d'origine et d'ajouter drop_first=True à l'appel get_dummies() pour empêcher le piège des varaibles multiples\n",
    "# pour éviter l'encodage d'info dupliquées\n",
    "# Obtenir les varaibles dummies\n",
    "subgrade_dummies=pd.get_dummies(df['sub_grade'],drop_first=True)# ce qui évite l'encodage d'info dupliquée ainsi on obtient k-1 Dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb505e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour les 4 features\n",
    "dummies=pd.get_dummies(df[['verification_status','initial_list_status','purpose','application_type']],drop_first=True)# transformation en variable dummies\n",
    "df=df.drop(['verification_status','initial_list_status','purpose','application_type'],axis=1)\n",
    "df=pd.concat([df,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52940a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature home_ownership\n",
    "# evaluation des valeurs de cette feature\n",
    "df['home_ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4892820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on constate qu'il y a peu de personne dans Any et none , on va les mettre dans other\n",
    "# remplacer none et any par others en utlisant  ma méthode replace \n",
    "df['home_ownership']= df['home_ownership'].replace(['NONE','ANY'],'OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13060501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion en variable dummies\n",
    "dummies=pd.get_dummies(df['home_ownership'],drop_first=True)# transformation en variable dummies\n",
    "df=df.drop('home_ownership',axis=1)\n",
    "df=pd.concat([df,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b07aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2740c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature adress\n",
    "df['zip_code']=df['address'].apply(lambda adress: adress[-5:])# application de la fonction pour récupérer les 5 derniers chifress\n",
    "# il faut extraire le code postal ou le zip code depuis l'adresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion de cette colone zip_code en dummies\n",
    "# création d'une catégorie par zip_code\n",
    "df['zip_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a606f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(df['zip_code'],drop_first=True)# transformation en variable dummies\n",
    "df=df.drop('zip_code',axis=1)\n",
    "df=pd.concat([df,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237850cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression de la colone adresse\n",
    "df=df.drop('address',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f18b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature issue: on sait pas à lavance si un prêt sera émis ou pas en utilisant notre modèle \n",
    "# on peut l'éliminer \n",
    "df=df.drop('issue_d',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c92ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature earliest_cr_line\n",
    "# extraction de l'année depuis cette feature\n",
    "df['earliest_cr_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d677ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['earliest_cr_line']= df['earliest_cr_line'].apply(lambda date: int(date[-4:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e37d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['earliest_cr_line']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15035109",
   "metadata": {},
   "source": [
    "# Repartition entre données d'entraînement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b498924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression de la colonne loan_status créée précédement car c'est une info dupliquée de la colonne loan_repaid\n",
    "df=df.drop('loan_status',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c6da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: pour les features\n",
    "#y: pour le label à prédir c'est à dire loan_repaid\n",
    "X=df.drop('loan_repaid',axis=1).values# pour avoir juste les valeurs et satisfaire tensor flow\n",
    "y=df['loan_repaid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d0cfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation des données\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X_train)# Application de la méthode fit_transform uniquement sur les données d'entraînement\n",
    "X_test=scaler.transform(X_test) # pour les données test on n'adapte pas on les transorme seulement pour éviter toute fuite de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85baa1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "# il semble avoir 81 features et on va faire correspondre ce nombre à la première couche\n",
    "# la première couche doit correspondre au nombre de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(units=81,activation='relu'))# Première couche (couche d'entrée/input layer)\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=41,activation='relu'))# 1ère couche cacheé\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=40,activation='relu'))# 2ème couche cacheé\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))# couche de sortie (ouptut layer)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e452a1",
   "metadata": {},
   "source": [
    "- Utilisation des call backs pour les arrêts anticipés de l'entrâinement  dans le but contrôler le surapprentissage\n",
    "- Ce qui permet de determiner le bon nombre d'epochs \n",
    "- montiror: contrôler la perte de validation\n",
    "- min_delta: changement minimum requis\n",
    "- patience: nombre d'epochs avec aucune amélioration avec le quel l'entrainement s'arrête\n",
    "- mode: c'est ce qu'on éssaie de faire: soit min: minimiser les éléments monitorés ex(la loss)\n",
    "- si notre métrique est une accuracy par exemple: on devrait maximiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7566f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,epochs=100,batch_size=256,validation_data=(X_test,y_test),callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75acbecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer la perte\n",
    "losses=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "# comme il s'agit d'un classification binaire on ajoute >0.5 et convertir en entier 0et 1 avec astype\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "y_pred=(model.predict(X_test)>0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019e61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rapport de classification\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73ec5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparaison avec le dataframe d'origine\n",
    "df['loan_repaid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "285936/len(df)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a0dec20",
   "metadata": {},
   "source": [
    "Prédiction pour un nouveau client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import random\n",
    "random.seed(102)\n",
    "random_ind= random.randint(0,len(df))# création d'un index aléatoire et à partir de cet index on prend un client et on lui  retire la valeur du label et on affiche\n",
    "# ces features\n",
    "\n",
    "new_client= df.drop('loan_repaid',axis=1).iloc[random_ind]\n",
    "new_client"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27437d19",
   "metadata": {},
   "source": [
    "Appliquer reshape pour qu'il soit de la même forme que les données d'entraînement sur lequel les données ont été adaptées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ec28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_client=scaler.transform(new_client.values.reshape(1,81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5281ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model.predict(new_client)>0.5).astype('int32')\n",
    "# le modèl prédit la classe 1 donc il finira par rembourser son prêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifions si la personne a vraiment rembourser: on va vérifier la valeur  de la colonne loan_repaid qui est le label à prédire \n",
    "df.iloc[random_ind]['loan_repaid']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
